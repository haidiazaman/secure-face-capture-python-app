{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a903f1d4",
   "metadata": {},
   "source": [
    "# python app - original gojek hackathon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af328fd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from glob import glob\n",
    "import csv\n",
    "from collections import OrderedDict\n",
    "import sys\n",
    "sys.path.append('./RF')\n",
    "from models.retinaface import RetinaFace\n",
    "from data import cfg_mnet\n",
    "from test_retina import infer\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import argparse\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.distributed as dist\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from pathlib import Path\n",
    "from scipy.special import softmax\n",
    "from tqdm.contrib.concurrent import process_map\n",
    "from torchvision.transforms import Compose, ToTensor\n",
    "import matplotlib.patches as patches\n",
    "from eye_net import *\n",
    "\n",
    "device=torch.device('cpu')\n",
    "\n",
    "# generate mouth boxes\n",
    "def get_mouth_box(face_landmarks,height_multiplier):\n",
    "    left_mouth,right_mouth=face_landmarks[6:8],face_landmarks[8:10]\n",
    "    lx,ly=left_mouth\n",
    "    rx,ry=right_mouth\n",
    "    l,r=lx,rx\n",
    "    mouth_box_width=r-l\n",
    "    mouth_box_height=mouth_box_width*height_multiplier\n",
    "    t=ly-mouth_box_height/2\n",
    "    b=ry+mouth_box_height/2\n",
    "    \n",
    "    return [int(l),int(t),int(r),int(b)]\n",
    "\n",
    "# generate eye boxes\n",
    "def get_eye_boxes(face_landmarks,eye_multiplier):\n",
    "    face_landmarks=np.array(face_landmarks).reshape(5,2)\n",
    "    left_eye_landmark=face_landmarks[0]\n",
    "    lx,ly=left_eye_landmark\n",
    "    right_eye_landmark=face_landmarks[1]\n",
    "    rx,ry=right_eye_landmark\n",
    "    eye_box_width = (rx-lx)/eye_multiplier\n",
    "    eye_box_height = eye_box_width\n",
    "    left_l,left_t,left_r,left_b=lx-eye_box_width*0.5,ly-eye_box_height*0.5,lx+eye_box_width*0.5,ly+eye_box_height*0.5\n",
    "    right_l,right_t,right_r,right_b=rx-eye_box_width*0.5,ry-eye_box_height*0.5,rx+eye_box_width*0.5,ry+eye_box_height*0.5    \n",
    "    left_eye_bbox = [int(left_l),int(left_t),int(left_r),int(left_b)]\n",
    "    right_eye_bbox = [int(right_l),int(right_t),int(right_r),int(right_b)]\n",
    "    return left_eye_bbox,right_eye_bbox\n",
    "\n",
    "# load image function for eye blink model\n",
    "def load_image_eyes(image,left_bbox,right_bbox):\n",
    "    expend_ratio = 0\n",
    "#     image = cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n",
    "    l, t, r, b = left_bbox\n",
    "    w, h = r - l, b - t\n",
    "    l, r = max(0, l - int(expend_ratio * w / 2)), min(image.shape[1] - 1, r + int(expend_ratio * w / 2))\n",
    "    t, b = max(0, t - int(expend_ratio * h / 2)), min(image.shape[0] - 1, b + int(expend_ratio * h / 2))\n",
    "    image1 = cv2.resize(image[t:b, l:r], (80, 80))\n",
    "    \n",
    "    l, t, r, b = right_bbox\n",
    "    w, h = r - l, b - t\n",
    "    l, r = max(0, l - int(expend_ratio * w / 2)), min(image.shape[1] - 1, r + int(expend_ratio * w / 2))\n",
    "    t, b = max(0, t - int(expend_ratio * h / 2)), min(image.shape[0] - 1, b + int(expend_ratio * h / 2))\n",
    "    image2 = cv2.resize(image[t:b, l:r], (80, 80))\n",
    "    \n",
    "    input_transform = Compose([\n",
    "        ToTensor(),\n",
    "    ])\n",
    "        \n",
    "    left_image = input_transform(np.array(image1, np.float32) / 255)\n",
    "    right_image = input_transform(np.array(image2, np.float32) / 255)\n",
    "\n",
    "    return left_image,right_image\n",
    "\n",
    "def load_mouth_tensor(image,bbox):\n",
    "    l,t,r,b=bbox\n",
    "    image = cv2.resize(image[t:b, l:r], (80, 80))\n",
    "    input_transform = Compose([\n",
    "        ToTensor(),\n",
    "    ])  \n",
    "    image = input_transform(np.array(image, np.float32) / 255)\n",
    "    return image\n",
    "\n",
    "# initialise RetinaFace face detector model\n",
    "cfg = cfg_mnet\n",
    "mode = 'test'\n",
    "\n",
    "face_detector_model = RetinaFace(cfg=cfg, phase=mode)\n",
    "model_weight_path = '/Users/haidiazaman/Desktop/secure-face-capture-python-app/haidi_gojek_hackathon_codes/RF/weights/old_weights/mobilenet0.25_best.pth'\n",
    "\n",
    "state_dict = torch.load(model_weight_path, map_location=device)\n",
    "new_state_dict = OrderedDict()\n",
    "\n",
    "for k, v in state_dict.items():\n",
    "    head = k[:7]\n",
    "    if head == 'module.':\n",
    "        name = k[7:]  # remove `module.`\n",
    "    else:\n",
    "        name = k\n",
    "    new_state_dict[name] = v\n",
    "\n",
    "face_detector_model.load_state_dict(new_state_dict)\n",
    "\n",
    "face_detector_model = face_detector_model.to(device)\n",
    "_ = face_detector_model.eval()\n",
    "\n",
    "confidence_threshold = cfg['infer_confidence_threshold']\n",
    "nms_threshold = cfg['infer_nms_threshold']  # 0.4\n",
    "iou_thresh = cfg['infer_iou_thresh']  # 0.5\n",
    "img_dim = cfg['infer_image_size']\n",
    "\n",
    "# initialise Eye blink model to detect eye blocking\n",
    "\n",
    "eye_blink_model_path='/Users/haidiazaman/Desktop/secure-face-capture-python-app/haidi_gojek_hackathon_codes/weights/eyeblink_model_epoch908.pt'\n",
    "eye_blink_model = Eye_Net('mobilenetv3_small_050',in_channel = 3, num_classes=3)\n",
    "_ = eye_blink_model.to(device)\n",
    "\n",
    "eye_blink_model.load_state_dict(torch.load(eye_blink_model_path, map_location = device))\n",
    "_ = eye_blink_model.eval()\n",
    "\n",
    "# initialise Mouth block model to detect eye blocking\n",
    "\n",
    "\n",
    "mouth_block_model_path='/Users/haidiazaman/Desktop/secure-face-capture-python-app/haidi_gojek_hackathon_codes/weights/mouthblock_model_epoch910.pt'\n",
    "mouth_block_model = Eye_Net('mobilenetv3_small_050',in_channel = 3, num_classes=2)\n",
    "_ = mouth_block_model.to(device)\n",
    "\n",
    "mouth_block_model.load_state_dict(torch.load(mouth_block_model_path, map_location = device))\n",
    "_ = mouth_block_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d47eb3",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "\n",
    "height_multiplier=0.9\n",
    "eye_multiplier=2\n",
    "cap=cv2.VideoCapture(0)\n",
    "block_threshold = 0.8\n",
    "\n",
    "while True:\n",
    "    start_time=time.time()\n",
    "    # Read a frame from the webcam\n",
    "    ret, image = cap.read() #image is in BGR\n",
    "    image=image[100:650,300:900]\n",
    "    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "    left_eye_store=[]\n",
    "    right_eye_store=[]\n",
    "    mouth_store=[]\n",
    "    SMOOTHING_WINDOW=20\n",
    "    try:\n",
    "        # get face detector - face box and face landmarks\n",
    "        dets, img_raw = infer(face_detector_model, image, img_dim, device, cfg, confidence_threshold, nms_threshold)\n",
    "        for det in dets:\n",
    "            l,t,r,b=det[:4]\n",
    "            face_bbox=[int(l),int(t),int(r),int(b)]\n",
    "            face_score=det[4]\n",
    "            face_landmarks=det[5:]\n",
    "            left_eye=face_landmarks[:2]\n",
    "            right_eye=face_landmarks[2:4]\n",
    "\n",
    "            # Draw rectangles around the detected faces\n",
    "            l,t,r,b=face_bbox\n",
    "            cv2.rectangle(image, (l, t), (r, b), (255,0, 0), 2) #(255, 0, 0)this is color in BGR\n",
    "            # Display face score beside the face bounding box\n",
    "            text = f\"Score: {face_score:.2f}\"\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "            org = (l, t - 10)  # Place the text slightly above the face bounding box\n",
    "            fontScale = 0.5\n",
    "            color = (255, 255, 255)\n",
    "            thickness = 1\n",
    "            image = cv2.putText(image, text, org, font, fontScale, color, thickness, cv2.LINE_AA, False)\n",
    "\n",
    "            \n",
    "            # generate eye boxes and pass into eye blink model to get score\n",
    "            # if detect open or close, plot green box, else red box           \n",
    "            left_eye_bbox,right_eye_bbox = get_eye_boxes(face_landmarks,eye_multiplier)\n",
    "            left_image,right_image=load_image_eyes(image,left_eye_bbox,right_eye_bbox)\n",
    "            left_image,right_image=left_image.to(device),right_image.to(device)\n",
    "            \n",
    "            left_logits=eye_blink_model(left_image.unsqueeze(0)).cpu().detach().numpy()\n",
    "            left_softmax_output=softmax(left_logits)\n",
    "#             left_prediction=np.argmax(left_softmax_output)\n",
    "            left_eye_store.append(left_softmax_output[0] [-1])\n",
    "            \n",
    "            right_logits=eye_blink_model(right_image.unsqueeze(0)).cpu().detach().numpy()\n",
    "            right_softmax_output=softmax(right_logits)\n",
    "#             right_prediction=np.argmax(right_softmax_output)\n",
    "            right_eye_store.append(right_softmax_output[0] [-1])\n",
    "            \n",
    "#             print(np.mean(left_eye_store[-SMOOTHING_WINDOW:]))\n",
    "#             print(np.mean(right_eye_store[-SMOOTHING_WINDOW:]))\n",
    "            left_block_score=np.mean(left_eye_store[-SMOOTHING_WINDOW:])\n",
    "            right_block_score=np.mean(right_eye_store[-SMOOTHING_WINDOW:])\n",
    "            if left_block_score>block_threshold:\n",
    "                l,t,r,b=left_eye_bbox\n",
    "                cv2.rectangle(image, (l, t), (r, b), (0,0, 255), 2) #(255, 0, 0)this is color in BGR\n",
    "\n",
    "                # Display face score beside the face bounding box\n",
    "                text = f\"Left Block Score: {left_block_score:.2f}\"\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                org = (l, t - 10)  # Place the text slightly above the face bounding box\n",
    "                fontScale = 0.5\n",
    "                color = (255, 255, 255)\n",
    "                thickness = 1\n",
    "                image = cv2.putText(image, text, org, font, fontScale, color, thickness, cv2.LINE_AA, False)\n",
    "\n",
    "                # plot caption to tell user to remove blocking item\n",
    "                text=f\"Left eye blocked!\"\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "                org = (20, 100) \n",
    "                fontScale = 1\n",
    "                color = (0,0,255) #BGR\n",
    "                thickness = 2\n",
    "                image = cv2.putText(image, text, org, font, fontScale,  color, thickness, cv2.LINE_AA, False) \n",
    "            else:\n",
    "                l,t,r,b=left_eye_bbox\n",
    "                cv2.rectangle(image, (l, t), (r, b), (0,255,0), 2) #(255, 0, 0)this is color in BGR\n",
    "                \n",
    "            if right_block_score>block_threshold:\n",
    "                l,t,r,b=right_eye_bbox\n",
    "                cv2.rectangle(image, (l, t), (r, b), (0,0, 255), 2) #(255, 0, 0)this is color in BGR\n",
    "\n",
    "                # Display face score beside the face bounding box\n",
    "                text = f\"Right Block Score: {right_block_score:.2f}\"\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                org = (l, t - 10)  # Place the text slightly above the face bounding box\n",
    "                fontScale = 0.5\n",
    "                color = (255, 255, 255)\n",
    "                thickness = 1\n",
    "                image = cv2.putText(image, text, org, font, fontScale, color, thickness, cv2.LINE_AA, False)\n",
    "\n",
    "                # plot caption to tell user to remove blocking item\n",
    "                text=f\"Right eye blocked!\"\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "                org = (300, 100) \n",
    "                fontScale = 1\n",
    "                color = (0,0,255) #BGR\n",
    "                thickness = 2\n",
    "                image = cv2.putText(image, text, org, font, fontScale,  color, thickness, cv2.LINE_AA, False) \n",
    "            else:\n",
    "                l,t,r,b=right_eye_bbox\n",
    "                cv2.rectangle(image, (l, t), (r, b), (0,255,0), 2) #(255, 0, 0)this is color in BGR\n",
    "            \n",
    "            # generate mouth boxes and pass into mouth block model to get score\n",
    "            # if detect not block, plot green box, else red box\n",
    "            mouth_box=get_mouth_box(face_landmarks,height_multiplier)\n",
    "            mouth_image=load_mouth_tensor(image,mouth_box)\n",
    "            mouth_logits=mouth_block_model(mouth_image.unsqueeze(0)).cpu().detach().numpy()\n",
    "            mouth_softmax_output=softmax(mouth_logits)\n",
    "#             mouth_prediction=np.argmax(mouth_softmax_output)\n",
    "            mouth_store.append(mouth_softmax_output[0][-1])\n",
    "            mouth_block_score=np.mean(mouth_store[-SMOOTHING_WINDOW:])\n",
    "\n",
    "            if mouth_block_score>block_threshold:\n",
    "                l,t,r,b=mouth_box\n",
    "                cv2.rectangle(image, (l, t), (r, b), (0,0, 255), 2) #(255, 0, 0)this is color in BGR\n",
    "\n",
    "                # Display face score beside the face bounding box\n",
    "                text = f\"Mouth Block Score: {mouth_block_score:.2f}\"\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "                org = (l, t - 10)  # Place the text slightly above the face bounding box\n",
    "                fontScale = 0.5\n",
    "                color = (255, 255, 255)\n",
    "                thickness = 1\n",
    "                image = cv2.putText(image, text, org, font, fontScale, color, thickness, cv2.LINE_AA, False)\n",
    "                \n",
    "                # plot caption to tell user to remove blocking item\n",
    "                text=f\"Mouth blocked!\"\n",
    "                font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "                org = (250,450) \n",
    "                fontScale = 1\n",
    "                color = (0,0,255) #BGR\n",
    "                thickness = 2\n",
    "                image = cv2.putText(image, text, org, font, fontScale,  color, thickness, cv2.LINE_AA, False) \n",
    "            else:\n",
    "                l,t,r,b=mouth_box\n",
    "                cv2.rectangle(image, (l, t), (r, b), (0,255,0), 2) #(255, 0, 0)this is color in BGR\n",
    "                \n",
    "\n",
    "            # Display the frame with detected faces\n",
    "            end_time=time.time()-start_time\n",
    "            text=f\"Inference time: {end_time:.2f} seconds\"\n",
    "            font = cv2.FONT_HERSHEY_SIMPLEX \n",
    "            org = (40, 40) \n",
    "            fontScale = 0.75\n",
    "            color = (255,255,255) \n",
    "            thickness = 2\n",
    "            image = cv2.putText(image, text, org, font, fontScale,  color, thickness, cv2.LINE_AA, False) \n",
    "            cv2.imshow('Face Detection', image)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    \n",
    "    # Break the loop when 'q' key is pressed\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "# Release the webcam and close the window\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8181fcf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dsa5204",
   "language": "python",
   "name": "dsa5204"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
